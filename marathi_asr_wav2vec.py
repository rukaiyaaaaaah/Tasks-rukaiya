# -*- coding: utf-8 -*-
"""Marathi-asr-wav2vec.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1zbdsxVQdMmoQULdpMAnD5VjrDd7nEByQ
"""

!pip install transformers torchaudio

import torch
import torchaudio
import re
from transformers import Wav2Vec2ForCTC, Wav2Vec2Processor

# Initialize processor and model
processor = Wav2Vec2Processor.from_pretrained("sumedh/wav2vec2-large-xlsr-marathi")
model = Wav2Vec2ForCTC.from_pretrained("sumedh/wav2vec2-large-xlsr-marathi")
model.to("cuda")

# Define resampler and regex of characters to ignore
resampler = torchaudio.transforms.Resample(48_000, 16_000)
chars_to_ignore_regex = '[\,\?\.\!\-\;\:\"\â€œ]'

def transcribe_audio(audio_path):
    # Load and resample the audio file
    speech_array, sampling_rate = torchaudio.load(audio_path)
    speech = resampler(speech_array).squeeze().numpy()

    # Preprocess the audio
    inputs = processor(speech, sampling_rate=16_000, return_tensors="pt", padding=True)

    # Model inference
    with torch.no_grad():
        logits = model(inputs.input_values.to("cuda"), attention_mask=inputs.attention_mask.to("cuda")).logits

    # Decode and print the predicted transcript
    pred_ids = torch.argmax(logits, dim=-1)
    return processor.batch_decode(pred_ids)[0]

audio_path = "/content/audio.mp3"
transcribed_text = transcribe_audio(audio_path)
print("Transcription:", transcribed_text)