{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8LA0sjx521Ws"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "os.chdir('/content')\n",
        "CODE_DIR = 'SAM'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1wYginBN26b3",
        "outputId": "c6cb051e-088e-4747-aae4-430a4710124f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'SAM'...\n",
            "remote: Enumerating objects: 228, done.\u001b[K\n",
            "remote: Counting objects: 100% (36/36), done.\u001b[K\n",
            "remote: Compressing objects: 100% (23/23), done.\u001b[K\n",
            "remote: Total 228 (delta 22), reused 13 (delta 13), pack-reused 192\u001b[K\n",
            "Receiving objects: 100% (228/228), 24.63 MiB | 26.47 MiB/s, done.\n",
            "Resolving deltas: 100% (75/75), done.\n"
          ]
        }
      ],
      "source": [
        "!git clone https://github.com/yuval-alaluf/SAM.git $CODE_DIR"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gf6WZkHJ2gA5",
        "outputId": "a1e527bb-dd6f-42e7-ced1-393cccfae477"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2023-11-27 11:14:15--  https://github.com/ninja-build/ninja/releases/download/v1.8.2/ninja-linux.zip\n",
            "Resolving github.com (github.com)... 140.82.113.4\n",
            "Connecting to github.com (github.com)|140.82.113.4|:443... connected.\n",
            "HTTP request sent, awaiting response... 302 Found\n",
            "Location: https://objects.githubusercontent.com/github-production-release-asset-2e65be/1335132/d2f252e2-9801-11e7-9fbf-bc7b4e4b5c83?X-Amz-Algorithm=AWS4-HMAC-SHA256&X-Amz-Credential=AKIAIWNJYAX4CSVEH53A%2F20231127%2Fus-east-1%2Fs3%2Faws4_request&X-Amz-Date=20231127T111416Z&X-Amz-Expires=300&X-Amz-Signature=409bd8b3ce258cf2d0186a7a69667da00fb55af2cae9729e4e19a22caf7cedfc&X-Amz-SignedHeaders=host&actor_id=0&key_id=0&repo_id=1335132&response-content-disposition=attachment%3B%20filename%3Dninja-linux.zip&response-content-type=application%2Foctet-stream [following]\n",
            "--2023-11-27 11:14:16--  https://objects.githubusercontent.com/github-production-release-asset-2e65be/1335132/d2f252e2-9801-11e7-9fbf-bc7b4e4b5c83?X-Amz-Algorithm=AWS4-HMAC-SHA256&X-Amz-Credential=AKIAIWNJYAX4CSVEH53A%2F20231127%2Fus-east-1%2Fs3%2Faws4_request&X-Amz-Date=20231127T111416Z&X-Amz-Expires=300&X-Amz-Signature=409bd8b3ce258cf2d0186a7a69667da00fb55af2cae9729e4e19a22caf7cedfc&X-Amz-SignedHeaders=host&actor_id=0&key_id=0&repo_id=1335132&response-content-disposition=attachment%3B%20filename%3Dninja-linux.zip&response-content-type=application%2Foctet-stream\n",
            "Resolving objects.githubusercontent.com (objects.githubusercontent.com)... 185.199.110.133, 185.199.109.133, 185.199.111.133, ...\n",
            "Connecting to objects.githubusercontent.com (objects.githubusercontent.com)|185.199.110.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 77854 (76K) [application/octet-stream]\n",
            "Saving to: ‘ninja-linux.zip’\n",
            "\n",
            "ninja-linux.zip     100%[===================>]  76.03K  --.-KB/s    in 0.01s   \n",
            "\n",
            "2023-11-27 11:14:16 (5.34 MB/s) - ‘ninja-linux.zip’ saved [77854/77854]\n",
            "\n",
            "Archive:  ninja-linux.zip\n",
            "  inflating: /usr/local/bin/ninja    \n",
            "update-alternatives: using /usr/local/bin/ninja to provide /usr/bin/ninja (ninja) in auto mode\n"
          ]
        }
      ],
      "source": [
        "!wget https://github.com/ninja-build/ninja/releases/download/v1.8.2/ninja-linux.zip\n",
        "!sudo unzip ninja-linux.zip -d /usr/local/bin/\n",
        "!sudo update-alternatives --install /usr/bin/ninja ninja /usr/local/bin/ninja 1 --force"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "SSXB_SzH3Azj"
      },
      "outputs": [],
      "source": [
        "os.chdir(f'./{CODE_DIR}')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hvYq44d42jln"
      },
      "outputs": [],
      "source": [
        "from argparse import Namespace\n",
        "import os\n",
        "import sys\n",
        "import pprint\n",
        "import numpy as np\n",
        "from PIL import Image\n",
        "import torch\n",
        "import torchvision.transforms as transforms\n",
        "\n",
        "sys.path.append(\".\")\n",
        "sys.path.append(\"..\")\n",
        "\n",
        "from datasets.augmentations import AgeTransformer\n",
        "from utils.common import tensor2im\n",
        "from models.psp import pSp"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "o7TGvGti2mkR"
      },
      "outputs": [],
      "source": [
        "EXPERIMENT_TYPE = 'ffhq_aging'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "boSf4UrI2vgR"
      },
      "outputs": [],
      "source": [
        "def get_download_model_command(file_id, file_name):\n",
        "    \"\"\" Get wget download command for downloading the desired model and save to directory ../pretrained_models. \"\"\"\n",
        "    current_directory = os.getcwd()\n",
        "    save_path = os.path.join(os.path.dirname(current_directory), \"pretrained_models\")\n",
        "    if not os.path.exists(save_path):\n",
        "        os.makedirs(save_path)\n",
        "    url = r\"\"\"wget --load-cookies /tmp/cookies.txt \"https://docs.google.com/uc?export=download&confirm=$(wget --quiet --save-cookies /tmp/cookies.txt --keep-session-cookies --no-check-certificate 'https://docs.google.com/uc?export=download&id={FILE_ID}' -O- | sed -rn 's/.*confirm=([0-9A-Za-z_]+).*/\\1\\n/p')&id={FILE_ID}\" -O {SAVE_PATH}/{FILE_NAME} && rm -rf /tmp/cookies.txt\"\"\".format(FILE_ID=file_id, FILE_NAME=file_name, SAVE_PATH=save_path)\n",
        "    return url"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BGcjgnlX3Lup"
      },
      "outputs": [],
      "source": [
        "MODEL_PATHS = {\n",
        "    \"ffhq_aging\": {\"id\": \"1XyumF6_fdAxFmxpFcmPf-q84LU_22EMC\", \"name\": \"sam_ffhq_aging.pt\"}\n",
        "}\n",
        "\n",
        "path = MODEL_PATHS[EXPERIMENT_TYPE]\n",
        "download_command = get_download_model_command(file_id=path[\"id\"], file_name=path[\"name\"])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ueSNOrE93Nx4",
        "outputId": "8a056650-af7b-470b-90ab-bc5f7120f6f3"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2023-11-27 11:15:54--  http://wget/\n",
            "Resolving wget (wget)... failed: Name or service not known.\n",
            "wget: unable to resolve host address ‘wget’\n",
            "--2023-11-27 11:15:54--  https://docs.google.com/uc?export=download&confirm=t&id=1XyumF6_fdAxFmxpFcmPf-q84LU_22EMC\n",
            "Resolving docs.google.com (docs.google.com)... 142.250.141.139, 142.250.141.138, 142.250.141.100, ...\n",
            "Connecting to docs.google.com (docs.google.com)|142.250.141.139|:443... connected.\n",
            "HTTP request sent, awaiting response... 303 See Other\n",
            "Location: https://doc-00-8g-docs.googleusercontent.com/docs/securesc/ha0ro937gcuc7l7deffksulhg5h7mbp1/b8hqv6skl6ef6qagnvrmockdenupcduo/1701083700000/05457687429326987275/*/1XyumF6_fdAxFmxpFcmPf-q84LU_22EMC?e=download&uuid=c2aa9106-b878-48ba-bc9c-189a96ef72a7 [following]\n",
            "Warning: wildcards not supported in HTTP.\n",
            "--2023-11-27 11:15:55--  https://doc-00-8g-docs.googleusercontent.com/docs/securesc/ha0ro937gcuc7l7deffksulhg5h7mbp1/b8hqv6skl6ef6qagnvrmockdenupcduo/1701083700000/05457687429326987275/*/1XyumF6_fdAxFmxpFcmPf-q84LU_22EMC?e=download&uuid=c2aa9106-b878-48ba-bc9c-189a96ef72a7\n",
            "Resolving doc-00-8g-docs.googleusercontent.com (doc-00-8g-docs.googleusercontent.com)... 74.125.137.132, 2607:f8b0:4023:c03::84\n",
            "Connecting to doc-00-8g-docs.googleusercontent.com (doc-00-8g-docs.googleusercontent.com)|74.125.137.132|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 2270547237 (2.1G) [application/x-zip]\n",
            "Saving to: ‘/content/pretrained_models/sam_ffhq_aging.pt’\n",
            "\n",
            "/content/pretrained 100%[===================>]   2.11G  67.6MB/s    in 34s     \n",
            "\n",
            "2023-11-27 11:16:29 (63.5 MB/s) - ‘/content/pretrained_models/sam_ffhq_aging.pt’ saved [2270547237/2270547237]\n",
            "\n",
            "FINISHED --2023-11-27 11:16:29--\n",
            "Total wall clock time: 35s\n",
            "Downloaded: 1 files, 2.1G in 34s (63.5 MB/s)\n"
          ]
        }
      ],
      "source": [
        "!wget {download_command}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2ff0Mpyj3PeN"
      },
      "outputs": [],
      "source": [
        "EXPERIMENT_DATA_ARGS = {\n",
        "    \"ffhq_aging\": {\n",
        "        \"model_path\": \"../pretrained_models/sam_ffhq_aging.pt\",\n",
        "        \"image_path\": \"/content/White-top.jpeg\",\n",
        "        \"transform\": transforms.Compose([\n",
        "            transforms.Resize((256, 256)),\n",
        "            transforms.ToTensor(),\n",
        "            transforms.Normalize([0.5, 0.5, 0.5], [0.5, 0.5, 0.5])])\n",
        "    }\n",
        "}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VZQBmeYz3RgO"
      },
      "outputs": [],
      "source": [
        "EXPERIMENT_ARGS = EXPERIMENT_DATA_ARGS[EXPERIMENT_TYPE]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "iYOGFnUL3VOQ"
      },
      "outputs": [],
      "source": [
        "model_path = EXPERIMENT_ARGS['model_path']\n",
        "ckpt = torch.load(model_path, map_location='cpu')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 246
        },
        "id": "hWOC4wqS4pXP",
        "outputId": "4adbde38-903d-47e9-b9a3-f7f2a27c49c2"
      },
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-14-289d4bd41723>\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mopts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mNamespace\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0mopts\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mnet\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpSp\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mopts\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mnet\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0meval\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mnet\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcuda\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Model successfully loaded!'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'opts' is not defined"
          ]
        }
      ],
      "source": [
        "opts = Namespace(**opts)\n",
        "net = pSp(opts)\n",
        "net.eval()\n",
        "net.cuda()\n",
        "print('Model successfully loaded!')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "s8zGn9Dh3XJf"
      },
      "outputs": [],
      "source": [
        "opts = ckpt['opts']\n",
        "pprint.pprint(opts)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5FqUjhns3Zf2"
      },
      "outputs": [],
      "source": [
        "opts['checkpoint_path'] = model_path"
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "37jmxTnqPkaK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Kocf8VeI3cjl"
      },
      "outputs": [],
      "source": [
        "image_path = EXPERIMENT_DATA_ARGS[EXPERIMENT_TYPE][\"image_path\"]\n",
        "original_image = Image.open(image_path).convert(\"RGB\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "x8OIKYor3r_v"
      },
      "outputs": [],
      "source": [
        "original_image.resize((256, 256))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wzksm6nr3srD"
      },
      "outputs": [],
      "source": [
        "!wget http://dlib.net/files/shape_predictor_68_face_landmarks.dat.bz2\n",
        "!bzip2 -dk shape_predictor_68_face_landmarks.dat.bz2"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fz1x3MZ93xJ3"
      },
      "outputs": [],
      "source": [
        "def run_alignment(image_path):\n",
        "    import dlib\n",
        "    from scripts.align_all_parallel import align_face\n",
        "    predictor = dlib.shape_predictor(\"shape_predictor_68_face_landmarks.dat\")\n",
        "    aligned_image = align_face(filepath=image_path, predictor=predictor)\n",
        "    print(\"Aligned image has shape: {}\".format(aligned_image.size))\n",
        "    return aligned_image"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QsH_58xq3zt1"
      },
      "outputs": [],
      "source": [
        "aligned_image = run_alignment(image_path)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "calM6LX53192"
      },
      "outputs": [],
      "source": [
        "aligned_image.resize((256, 256))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BEUrdMtp339j"
      },
      "outputs": [],
      "source": [
        "img_transforms = EXPERIMENT_ARGS['transform']\n",
        "input_image = img_transforms(aligned_image)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Yt29Q7T77yL-"
      },
      "outputs": [],
      "source": [
        "input_image"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "SwRXvAtK36TX"
      },
      "outputs": [],
      "source": [
        "target_ages = [0, 10, 20, 30, 40, 50, 60, 70, 80, 90, 100]\n",
        "age_transformers = [AgeTransformer(target_age=age) for age in target_ages]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cFN2Pp__38pt"
      },
      "outputs": [],
      "source": [
        "def run_on_batch(inputs, net):\n",
        "    result_batch = net(inputs.to(\"cuda\").float(), randomize_noise=False, resize=False)\n",
        "    return result_batch"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KN1qwBYnCFFp"
      },
      "outputs": [],
      "source": [
        "results = np.array(aligned_image.resize((1024, 1024)))\n",
        "for age_transformer in age_transformers:\n",
        "    print(f\"Running on target age: {age_transformer.target_age}\")\n",
        "    with torch.no_grad():\n",
        "        input_image_age = [age_transformer(input_image.cpu()).to('cuda')]\n",
        "        input_image_age = torch.stack(input_image_age)\n",
        "        result_tensor = run_on_batch(input_image_age, net)[0]\n",
        "        result_image = tensor2im(result_tensor)\n",
        "        results = np.concatenate([results, result_image], axis=1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9jlLvmnpCHoI"
      },
      "outputs": [],
      "source": [
        "results = Image.fromarray(results)\n",
        "results"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ucYmyikA3-wI"
      },
      "outputs": [],
      "source": [
        "import cv2\n",
        "import numpy as np\n",
        "import torch\n",
        "from torchvision.transforms.functional import to_pil_image\n",
        "\n",
        "def tensor2cvimage(tensor, size=(2048, 2048)):\n",
        "    image = to_pil_image(tensor).resize(size)\n",
        "    return cv2.cvtColor(np.array(image), cv2.COLOR_RGB2BGR)\n",
        "\n",
        "# Increased resolution for the video\n",
        "video_resolution = (2048, 2048)\n",
        "\n",
        "# Initialize video writer with higher resolution and lower FPS\n",
        "fourcc = cv2.VideoWriter_fourcc(*'mp4v')\n",
        "video_writer = cv2.VideoWriter('ruks.mp4', fourcc, 1.0, video_resolution)\n",
        "\n",
        "for age_transformer in age_transformers:\n",
        "    print(f\"Running on target age: {age_transformer.target_age}\")\n",
        "    with torch.no_grad():\n",
        "        input_image_age = [age_transformer(input_image.cpu()).to('cuda')]\n",
        "        input_image_age = torch.stack(input_image_age)\n",
        "        result_tensor = run_on_batch(input_image_age, net)[0]\n",
        "        result_image = tensor2im(result_tensor)\n",
        "\n",
        "        # Resize, convert to OpenCV image format, and write to video\n",
        "        cv_image = tensor2cvimage(result_tensor, size=video_resolution)\n",
        "        video_writer.write(cv_image)\n",
        "\n",
        "# Release the video writer\n",
        "video_writer.release()\n"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}